{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Gabriela Yukari Mitu\n",
    "\n",
    "Nome: Gabriella Escobar Cukier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@gabriela_ymitu***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @gabriela_ymitu\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Android'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 1000\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=pd.read_excel('Android.xlsx','Treinamento',sep=',')\n",
    "dfc=pd.read_excel('Android.xlsx', 'Teste',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#limpo = re.sub(\"\\.{1,}\", \"?\", \"dft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1=['  ','   ',':','(',')','`','[',']','.','/','\" ',\"'\"]\n",
    "lista2=[' ',' ',' ',' ',' ',' ',' ',' ',' ',' ',' ',' ']\n",
    "for i in range(len(lista1)):\n",
    "    dft['Treinamento']=dft.Treinamento.str.replace(lista1[i], lista2[i])\n",
    "    dfc['Teste']=dfc.Teste.str.replace(lista1[i], lista2[i])\n",
    "dft['Treinamento']=dft.Treinamento.str.lower()\n",
    "dfc['Teste']=dfc.Teste.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['Treinamento']=dft['Treinamento'].str.split()\n",
    "dfc['Teste']=dfc['Teste'].str.split()\n",
    "dft['Treinamento'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftLen=len(dft)\n",
    "\n",
    "dftIrre=dft[dft['Relevância']==0]\n",
    "dftIrreLen=len(dftIrre)\n",
    "\n",
    "dftNeutro=dft[dft['Relevância']==1]\n",
    "dftNeutroLen=len(dftNeutro)\n",
    "\n",
    "dftRelev=dft[dft['Relevância']==2]\n",
    "dftRelevLen=len(dftRelev)\n",
    "\n",
    "dftMtRelev=dft[dft['Relevância']==3]\n",
    "dftMtRelevLen=len(dftMtRelev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de palavras dado sua categoria\n",
    "#Irrelevante\n",
    "dftIrreProb=dftRelev[\"Treinamento\"].sum()\n",
    "dftIrreProb=pd.Series(dftIrreProb)\n",
    "dftIrreProb=dftIrreProb.value_counts()\n",
    "\n",
    "#Neutro\n",
    "dftNeutroProb=dftNeutro[\"Treinamento\"].sum()\n",
    "dftNeutroProb=pd.Series(dftNeutroProb)\n",
    "dftNeutroProb=dftNeutroProb.value_counts()\n",
    "\n",
    "#Relevante\n",
    "dftRelevProb=dftRelev[\"Treinamento\"].sum()\n",
    "dftRelevProb=pd.Series(dftRelevProb)\n",
    "dftRelevProb=dftRelevProb.value_counts()\n",
    "\n",
    "#Muito relevante\n",
    "dftMtRelevProb=dftMtRelev[\"Treinamento\"].sum()\n",
    "dftMtRelevProb=pd.Series(dftMtRelevProb)\n",
    "dftMtRelevProb=dftMtRelevProb.value_counts()\n",
    "\n",
    "#Total\n",
    "dftTotal=dft.Treinamento.sum()\n",
    "dftTotal=pd.Series(dftTotal)\n",
    "dftTotal=dftTotal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftPalavras=dft.Treinamento.sum()\n",
    "dftPalavras=pd.Series(dftPalavras)\n",
    "dftPalavras=len(dftPalavras)\n",
    "\n",
    "#Check de palavras\n",
    "check=dft.Treinamento.sum()\n",
    "check=pd.Series(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Números totais de palavras em cada categoria, mas agora em variáveis\n",
    "#Irrelevante\n",
    "IrrePalavras=dftIrre[\"Treinamento\"].sum()\n",
    "IrrePalavras=pd.Series(IrrePalavras)\n",
    "IrrePalavras=len(IrrePalavras)\n",
    "\n",
    "#Neutro\n",
    "NeutroPalavras=dftNeutro[\"Treinamento\"].sum()\n",
    "NeutroPalavras=pd.Series(NeutroPalavras)\n",
    "NeutroPalavras=len(NeutroPalavras)\n",
    "\n",
    "#Relevante\n",
    "RelevPalavras=dftRelev[\"Treinamento\"].sum()\n",
    "RelevPalavras=pd.Series(RelevPalavras)\n",
    "RelevPalavras=len(RelevPalavras)\n",
    "\n",
    "#Muito Relevante\n",
    "MtRelevPalavras=dftMtRelev[\"Treinamento\"].sum()\n",
    "MtRelevPalavras=pd.Series(MtRelevPalavras)\n",
    "MtRelevPalavras=len(MtRelevPalavras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades base\n",
    "ProbIrre=IrrePalavras/(dftPalavras)\n",
    "ProbNeutro=NeutroPalavras/(dftPalavras)\n",
    "ProbRelev=RelevPalavras/(dftPalavras)\n",
    "ProbMtRelev=MtRelevPalavras/(dftPalavras)\n",
    "\n",
    "print('A probablidade de ser Irrelevante é: {0:.3f} %'.format(ProbIrre*100))\n",
    "print('A probablidade de ser Neutro é: {0:.3f} %'.format(ProbNeutro*100))\n",
    "print('A probablidade de ser Relevante é: {0:.3f} %'.format(ProbRelev*100))\n",
    "print('A probablidade de ser Irrelevante  é: {0:.3f} %'.format(ProbMtRelev*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
